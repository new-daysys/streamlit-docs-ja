---
title: Caching overview
slug: /develop/concepts/architecture/caching
---

> [!Note]
> `@st.cache` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯å»ƒæ­¢ã•ã‚Œã¾ã—ãŸã€‚
> é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ [Optimize performance with st.cache](/develop/concepts/architecture/st.cache) ã«ã¦ç¢ºèªã§ãã¾ã™ã€‚

# ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ¦‚è¦

Streamlit ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ“ä½œã‚„ã‚³ãƒ¼ãƒ‰ã®å¤‰æ›´ãŒã‚ã‚‹ãŸã³ã«ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä¸Šã‹ã‚‰ä¸‹ã¾ã§å†å®Ÿè¡Œã—ã¾ã™ã€‚ã“ã®å®Ÿè¡Œãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šã€é–‹ç™ºãŒéå¸¸ã«ç°¡å˜ã«ãªã‚Šã¾ã™ãŒã€2ã¤ã®å¤§ããªèª²é¡Œã‚‚ã‚ã‚Šã¾ã™ï¼š

1. é•·æ™‚é–“å®Ÿè¡Œã•ã‚Œã‚‹é–¢æ•°ãŒä½•åº¦ã‚‚å†å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€ã‚¢ãƒ—ãƒªãŒé…ããªã‚‹ã€‚
2. ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒä½•åº¦ã‚‚å†ä½œæˆã•ã‚Œã‚‹ãŸã‚ã€å†å®Ÿè¡Œã‚„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã¾ãŸã„ã§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¿æŒã™ã‚‹ã®ãŒé›£ã—ããªã‚‹ã€‚

ã§ã‚‚å¿ƒé…ã—ãªã„ã§ãã ã•ã„ï¼Streamlitã«ã¯ã“ã‚Œã‚‰ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿèƒ½ãŒçµ„ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã¯ã€é…ã„é–¢æ•°å‘¼ã³å‡ºã—ã®çµæœã‚’ä¿å­˜ã—ã€å†å®Ÿè¡Œã‚’é¿ã‘ã‚‹ã“ã¨ã§ã‚¢ãƒ—ãƒªã‚’é«˜é€ŸåŒ–ã—ã€å†å®Ÿè¡Œæ™‚ã«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æŒç¶šã•ã›ã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå€¤ã¯ã‚¢ãƒ—ãƒªã®ã™ã¹ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ©ç”¨å¯èƒ½ã§ã™ã€‚ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªçµæœã‚’ä¿å­˜ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã¯ã€ä»£ã‚ã‚Šã«[ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ](/develop/concepts/architecture/session-state) ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

1. [å°ã•ãªä¾‹](#å°ã•ãªä¾‹)
2. [åŸºæœ¬çš„ãªä½¿ã„æ–¹](#åŸºæœ¬çš„ãªä½¿ã„æ–¹)
3. [é«˜åº¦ãªä½¿ã„æ–¹](#é«˜åº¦ãªä½¿ã„æ–¹)
4. [st.cacheã‹ã‚‰ã®ç§»è¡Œ](#st.cacheã‹ã‚‰ã®ç§»è¡Œ)

## å°ã•ãªä¾‹

Streamlit ã§é–¢æ•°ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã«ã¯ã€`st.cache_data` ã¾ãŸã¯ `st.cache_resource` ã®ã„ãšã‚Œã‹ã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§é–¢æ•°ã‚’è£…é£¾ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

```python
@st.cache_data
def long_running_function(param1, param2):
    return â€¦
```

ã“ã®ä¾‹ã§ã¯ã€`long_running_function` ã« `@st.cache_data` ã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ã§ã€Streamlitã¯é–¢æ•°ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹ãŸã³ã«ä»¥ä¸‹ã®2ã¤ã®ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ï¼š

1. å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€¤ï¼ˆã“ã®å ´åˆã€`param1` ã¨ `param2`ï¼‰ã€‚
2. é–¢æ•°å†…ã®ã‚³ãƒ¼ãƒ‰ã€‚

StreamlitãŒã“ã‚Œã‚‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ã¨é–¢æ•°ã‚³ãƒ¼ãƒ‰ã‚’åˆã‚ã¦ç¢ºèªã—ãŸå ´åˆã€é–¢æ•°ã‚’å®Ÿè¡Œã—ã€ãã®æˆ»ã‚Šå€¤ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã™ã€‚åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ã§å†åº¦å‘¼ã³å‡ºã•ã‚Œã‚‹ã¨ï¼ˆä¾‹ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ãƒ—ãƒªã‚’æ“ä½œã—ãŸå ´åˆï¼‰ã€Streamlitã¯é–¢æ•°ã®å®Ÿè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€ä»£ã‚ã‚Šã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå€¤ã‚’è¿”ã—ã¾ã™ã€‚é–‹ç™ºä¸­ã¯ã€é–¢æ•°ã‚³ãƒ¼ãƒ‰ãŒå¤‰æ›´ã•ã‚Œã‚‹ãŸã³ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè‡ªå‹•çš„ã«æ›´æ–°ã•ã‚Œã€æœ€æ–°ã®å¤‰æ›´ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«åæ˜ ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

å‰è¿°ã®ã¨ãŠã‚Šã€ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã«ã¯2ã¤ã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒã‚ã‚Šã¾ã™ï¼š

- `st.cache_data` ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™è¨ˆç®—ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«æ¨å¥¨ã•ã‚Œã¾ã™ã€‚ä¾‹ãˆã°ã€CSVã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®èª­ã¿è¾¼ã¿ã€NumPyé…åˆ—ã®å¤‰æ›ã€APIã‚¯ã‚¨ãƒªãªã©ã€ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆæ–‡å­—åˆ—ã€æ•´æ•°ã€æµ®å‹•å°æ•°ç‚¹æ•°ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€é…åˆ—ã€ãƒªã‚¹ãƒˆãªã©ï¼‰ã‚’è¿”ã™é–¢æ•°ã«é©ã—ã¦ã„ã¾ã™ã€‚é–¢æ•°ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹ãŸã³ã«ãƒ‡ãƒ¼ã‚¿ã®æ–°ã—ã„ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã™ã‚‹ãŸã‚ã€[ãƒŸãƒ¥ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ç«¶åˆçŠ¶æ…‹](#mutation-and-concurrency-issues)ã«å¯¾ã—ã¦å®‰å…¨ã§ã™ã€‚ã»ã¨ã‚“ã©ã®å ´åˆã€`st.cache_data` ã‚’ä½¿ç”¨ã™ã‚‹ã®ãŒé©åˆ‡ãªã®ã§ã€è¿·ã£ãŸå ´åˆã¯ `st.cache_data` ã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼
- `st.cache_resource` ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãªã©ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ãŸã‚ã«æ¨å¥¨ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã¯ã€è¤‡æ•°å›èª­ã¿è¾¼ã‚€å¿…è¦ã®ãªã„ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºä¸å¯èƒ½ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«é©ã—ã¦ãŠã‚Šã€ã‚¢ãƒ—ãƒªã®å†å®Ÿè¡Œã‚„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã¾ãŸã„ã§ãƒªã‚½ãƒ¼ã‚¹ã‚’å…±æœ‰ã§ãã¾ã™ã€‚ãŸã ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸæˆ»ã‚Šå€¤ã‚’å¤‰æ›´ã™ã‚‹ã¨ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚‚ç›´æ¥å¤‰æ›´ã•ã‚Œã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼ˆè©³ç´°ã¯å¾Œè¿°ï¼‰ã€‚

## åŸºæœ¬çš„ãªä½¿ã„æ–¹

### st.cache_data

`st.cache_data` ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€NumPyé…åˆ—ã€æ–‡å­—åˆ—ã€æ•´æ•°ã€æµ®å‹•å°æ•°ç‚¹æ•°ãªã©ã€ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ã™ã¹ã¦ã®é–¢æ•°ã«ä½¿ç”¨ã™ã‚‹åŸºæœ¬çš„ãªã‚³ãƒãƒ³ãƒ‰ã§ã™ã€‚ã»ã¨ã‚“ã©ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«é©ã—ã¦ã„ã‚‹ãŸã‚ã€ã“ã‚ŒãŒä¸»ãªä½¿ç”¨æ–¹æ³•ã§ã™ã€‚å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã¯ã€`@st.cache_data` ã§è£…é£¾ã•ã‚ŒãŸé–¢æ•°ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸæˆ»ã‚Šå€¤ã®_ã‚³ãƒ”ãƒ¼_ã‚’è¿”ã—ã¾ã™ï¼ˆã™ã§ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰ã€‚

#### ä½¿ç”¨ä¾‹

`st.cache_data` ã®ä½¿ç”¨ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ä¾‹ãˆã°ã€ã‚¢ãƒ—ãƒªãŒ[Uberã®ãƒ©ã‚¤ãƒ‰ã‚·ã‚§ã‚¢ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://github.com/plotly/datasets/blob/master/uber-rides-data1.csv)ï¼ˆ50 MBã®CSVãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰DataFrameã«èª­ã¿è¾¼ã‚€å ´åˆã§ã™ï¼š

```python
def load_data(url):
    df = pd.read_csv(url)  # ğŸ‘ˆ ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    return df

df = load_data("https://github.com/plotly/datasets/raw/master/uber-rides-data1.csv")
st.dataframe(df)

st.button("Rerun")
```

`load_data` é–¢æ•°ã®å®Ÿè¡Œã«ã¯ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã«ã‚ˆã£ã¦ã¯2ã€œ30ç§’ã‹ã‹ã‚Šã¾ã™ã€‚ï¼ˆãƒ’ãƒ³ãƒˆ: å›ç·šãŒé…ã„å ´åˆã¯[ã“ã¡ã‚‰ã®5 MBãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://github.com/plotly/datasets/blob/master/26k-consumer-complaints.csv)ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼‰ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãªã—ã§ã¯ã€ã‚¢ãƒ—ãƒªãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ãŸã³ã€ã¾ãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ“ä½œã™ã‚‹ãŸã³ã«ãƒ‡ãƒ¼ã‚¿ãŒå†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚è¿½åŠ ã—ãŸãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼ã‚ã¾ã‚Šè‰¯ã„ä½“é¨“ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã‚ˆã­â€¦ ğŸ˜•

ã§ã¯ã€`load_data` ã« `@st.cache_data` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’è¿½åŠ ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
@st.cache_data  # ğŸ‘ˆ ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’è¿½åŠ 
def load_data(url):
    df = pd.read_csv(url)
    return df

df = load_data("https://github.com/plotly/datasets/raw/master/uber-rides-data1.csv")
st.dataframe(df)

st.button("Rerun")
```

ã‚¢ãƒ—ãƒªã‚’å†å®Ÿè¡Œã™ã‚‹ã¨ã€æœ€åˆã®å®Ÿè¡Œæ™‚ã®ã¿é…ã„ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒç™ºç”Ÿã—ã€æ¬¡å›ä»¥é™ã®å†å®Ÿè¡Œã¯ã»ã¼ç¬æ™‚ã«è¡Œã‚ã‚Œã¾ã™ï¼ğŸ’¨

#### å‹•ä½œ

ã“ã‚ŒãŒã©ã®ã‚ˆã†ã«å‹•ä½œã™ã‚‹ã®ã‹ã€`st.cache_data` ã®æŒ™å‹•ã‚’ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è¦‹ã¦ã„ãã¾ã—ã‚‡ã†ï¼š

- æœ€åˆã®å®Ÿè¡Œæ™‚ã€Streamlitã¯æŒ‡å®šã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ï¼ˆã“ã®å ´åˆã¯CSVãƒ•ã‚¡ã‚¤ãƒ«ã®URLï¼‰ã§ `load_data` é–¢æ•°ã‚’å‘¼ã³å‡ºã—ãŸã“ã¨ãŒãªã„ã“ã¨ã‚’èªè­˜ã—ã¾ã™ã€‚ãã“ã§ã€é–¢æ•°ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
- ã“ã“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒå‹•ä½œã—ã¾ã™ï¼šè¿”ã•ã‚ŒãŸDataFrameã¯[pickle](https://docs.python.org/3/library/pickle.html)ã‚’ä»‹ã—ã¦ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆã«å¤‰æ›ï¼‰ã•ã‚Œã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã•ã‚Œã¾ã™ï¼ˆ`url` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€¤ã¨å…±ã«ï¼‰ã€‚
- æ¬¡å›ã®å®Ÿè¡Œæ™‚ã€Streamlitã¯ç‰¹å®šã® `url` ã«å¯¾ã™ã‚‹ `load_data` ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’ç¢ºèªã—ã¾ã™ã€‚ã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚‹ã®ã§ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—ã—ã€ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºè§£é™¤ã—ã¦DataFrameã«å¤‰æ›ã—ã€é–¢æ•°ã‚’å†å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ä»£ã‚ã‚Šã«è¿”ã—ã¾ã™ã€‚

ã“ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã¨ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºè§£é™¤ã®ãƒ—ãƒ­ã‚»ã‚¹ã«ã‚ˆã‚Šã€å…ƒã®DataFrameã®ã‚³ãƒ”ãƒ¼ãŒä½œæˆã•ã‚Œã¾ã™ã€‚ã“ã®ã‚³ãƒ”ãƒ¼å‹•ä½œã¯ä¸€è¦‹ä¸è¦ã«æ€ãˆã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹éš›ã«ã¯æœ‰åŠ¹ã§ã‚ã‚Šã€ãƒŸãƒ¥ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ç«¶åˆçŠ¶æ…‹ã®å•é¡Œã‚’åŠ¹æœçš„ã«é˜²ãã¾ã™ã€‚è©³ã—ãã¯ã€ä»¥ä¸‹ã®ã€Œ[ãƒŸãƒ¥ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨ç«¶åˆçŠ¶æ…‹ã®å•é¡Œ](#mutation-and-concurrency-issues)ã€ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã”è¦§ãã ã•ã„ã€‚

> [!Warning]
> `st.cache_data` ã¯æš—é»™çš„ã« `pickle` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€ã“ã‚Œã¯å®‰å…¨æ€§ã«å•é¡ŒãŒã‚ã‚‹ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•°ãŒè¿”ã™ã‚‚ã®ã¯ã™ã¹ã¦pickleã•ã‚Œã¦ä¿å­˜ã•ã‚Œã€å–ã‚Šå‡ºã™éš›ã«unpickleã•ã‚Œã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•°ãŒä¿¡é ¼ã§ãã‚‹å€¤ã‚’è¿”ã™ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ä¸æ­£ãªpickleãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã—ã€unpickleæ™‚ã«ä»»æ„ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚ä¿¡é ¼ã§ããªã„ã‚½ãƒ¼ã‚¹ã‹ã‚‰æ¥ãŸå¯èƒ½æ€§ãŒã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ã€å®‰å…¨ã§ãªã„ãƒ¢ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¾ãªã„ã§ãã ã•ã„ã€‚**ä¿¡é ¼ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„**ã€‚

#### ä½¿ç”¨ä¾‹

**DataFrameã®å¤‰æ›**

ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€DataFrameã®èª­ã¿è¾¼ã¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã—ãŸã€‚`df.filter`ã€`df.apply`ã€`df.sort_values` ãªã©ã®DataFrameå¤‰æ›ã‚‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ãŒæœ‰åŠ¹ã§ã™ã€‚ç‰¹ã«å¤§è¦æ¨¡ãªDataFrameã§ã¯ã€ã“ã‚Œã‚‰ã®æ“ä½œã¯é…ããªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

```python
@st.cache_data
def transform(df):
    df = df.filter(items=['one', 'three'])
    df = df.apply(np.sum, axis=0)
	return df
```

**é…åˆ—ã®è¨ˆç®—**

åŒæ§˜ã«ã€NumPyé…åˆ—ã®è¨ˆç®—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã‚‚æ„å‘³ãŒã‚ã‚Šã¾ã™ï¼š

```python
@st.cache_data
def add(arr1, arr2):
	return arr1 + arr2
```

**ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª**

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ‰±ã†å ´åˆã€SQLã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ—ãƒªã«èª­ã¿è¾¼ã‚€ã“ã¨ãŒä¸€èˆ¬çš„ã§ã™ã€‚ã“ã‚Œã‚‰ã®ã‚¯ã‚¨ãƒªã‚’ç¹°ã‚Šè¿”ã—å®Ÿè¡Œã™ã‚‹ã®ã¯é…ããªã‚Šã€ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚Šã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚‚ä½ä¸‹ã•ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ãƒ—ãƒªå†…ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚è©³ç´°ãªä¾‹ã«ã¤ã„ã¦ã¯ã€[Streamlitã¨ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ¥ç¶šã™ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ‰](/develop/tutorials/databases)ã‚‚å‚ç…§ã—ã¦ãã ã•ã„ã€‚

```python
connection = database.connect()

@st.cache_data
def query():
    return pd.read_sql_query("SELECT * from table", connection)
```

> [!Tip]
> ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ–°ã—ã„çµæœã‚’å–å¾—ã™ã‚‹ãŸã‚ã« `ttl`ï¼ˆæœ‰åŠ¹æœŸé™ï¼‰ã‚’è¨­å®šã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚`st.cache_data(ttl=3600)` ã‚’è¨­å®šã™ã‚‹ã¨ã€Streamlitã¯1æ™‚é–“ï¼ˆ3600ç§’ï¼‰å¾Œã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå€¤ã‚’ç„¡åŠ¹åŒ–ã—ã€å†åº¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•°ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚è©³ç´°ã¯[ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚µã‚¤ã‚ºã¨æœŸé–“ã®åˆ¶å¾¡](#controlling-cache-size-and-duration)ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚

**APIå‘¼ã³å‡ºã—**

APIå‘¼ã³å‡ºã—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã®ã‚‚æœ‰åŠ¹ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å›é¿ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

```python
@st.cache_data
def api_call():
    response = requests.get('https://jsonplaceholder.typicode.com/posts/1')
    return response.json()
```

**MLãƒ¢ãƒ‡ãƒ«ã®å®Ÿè¡Œï¼ˆæ¨è«–ï¼‰**

è¤‡é›‘ãªæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€å¤šãã®æ™‚é–“ã¨ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚åŒã˜è¨ˆç®—ã‚’ä½•åº¦ã‚‚å†å®Ÿè¡Œã™ã‚‹ã®ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã€ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

```python
@st.cache_data
def run_model(inputs):
    return model(inputs)
```

### st.cache_resource

`st.cache_resource` ã¯ã€ã™ã¹ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã€ãŠã‚ˆã³å†å®Ÿè¡Œã§ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«åˆ©ç”¨ã§ãã‚‹ã€Œãƒªã‚½ãƒ¼ã‚¹ã€ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰ã§ã™ã€‚`st.cache_data` ã‚ˆã‚Šã‚‚é™å®šçš„ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’æŒã¡ã€ç‰¹ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚„æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«é©ã—ã¦ã„ã¾ã™ã€‚å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã€`@st.cache_resource` ã§è£…é£¾ã•ã‚ŒãŸé–¢æ•°ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸè¿”ã‚Šå€¤ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¿”ã—ã¾ã™ï¼ˆã™ã§ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰ã€‚ã—ãŸãŒã£ã¦ã€`st.cache_resource` ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã®ã‚ˆã†ã«æŒ¯ã‚‹èˆã„ã€ãƒŸãƒ¥ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

#### ä½¿ç”¨ä¾‹

`st.cache_resource` ã®ä¾‹ã¨ã—ã¦ã€å…¸å‹çš„ãªæ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ—ãƒªã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ã¾ãšã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã“ã§ã¯ã€[Hugging Faceã®transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒª](https://huggingface.co/docs/transformers/index)ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š

```python
from transformers import pipeline
model = pipeline("sentiment-analysis")  # ğŸ‘ˆ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
```

ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’Streamlitã‚¢ãƒ—ãƒªã«ç›´æ¥æ›¸ãè¾¼ã‚€ã¨ã€ã‚¢ãƒ—ãƒªã¯å†å®Ÿè¡Œã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ“ä½œã®ãŸã³ã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚ã“ã®ç¹°ã‚Šè¿”ã—ã®ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã«ã¯2ã¤ã®å•é¡ŒãŒã‚ã‚Šã¾ã™ï¼š

- ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«æ™‚é–“ãŒã‹ã‹ã‚Šã€ã‚¢ãƒ—ãƒªã®é€Ÿåº¦ãŒä½ä¸‹ã™ã‚‹ã€‚
- å„ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒãƒ¢ãƒ‡ãƒ«ã‚’æœ€åˆã‹ã‚‰èª­ã¿è¾¼ã‚€ãŸã‚ã€è†¨å¤§ãªãƒ¡ãƒ¢ãƒªã‚’æ¶ˆè²»ã™ã‚‹ã€‚

ä»£ã‚ã‚Šã«ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€åº¦ã ã‘èª­ã¿è¾¼ã¿ã€ã™ã¹ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§åŒã˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ã„å›ã™æ–¹ãŒåˆç†çš„ã§ã™ã€‚ã“ã‚Œã“ããŒ `st.cache_resource` ã®ä½¿ç”¨ä¾‹ã§ã™ï¼ã‚¢ãƒ—ãƒªã«è¿½åŠ ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
from transformers import pipeline

@st.cache_resource  # ğŸ‘ˆ ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’è¿½åŠ 
def load_model():
    return pipeline("sentiment-analysis")

model = load_model()

query = st.text_input("Your query", value="I love Streamlit! ğŸˆ")
if query:
    result = model(query)[0]  # ğŸ‘ˆ ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†é¡
    st.write(result)
```

ã“ã®ã‚¢ãƒ—ãƒªã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€`load_model` ã¯ã‚¢ãƒ—ãƒªã®èµ·å‹•æ™‚ã«1å›ã ã‘å‘¼ã³å‡ºã•ã‚Œã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã™ã€‚ä»¥é™ã®å†å®Ÿè¡Œã§ã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸåŒã˜ãƒ¢ãƒ‡ãƒ«ãŒå†åˆ©ç”¨ã•ã‚Œã€æ™‚é–“ã¨ãƒ¡ãƒ¢ãƒªãŒç¯€ç´„ã•ã‚Œã¾ã™ï¼

#### å‹•ä½œ

`st.cache_resource` ã®ä½¿ç”¨ã¯ `st.cache_data` ã«éå¸¸ã«ã‚ˆãä¼¼ã¦ã„ã¾ã™ãŒã€ã„ãã¤ã‹é‡è¦ãªé•ã„ãŒã‚ã‚Šã¾ã™ï¼š

- `st.cache_resource` ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸè¿”ã‚Šå€¤ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã›ãšã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆè‡ªä½“ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã™ã€‚ãã®ãŸã‚ã€é–¢æ•°ã®è¿”ã‚Šå€¤ã«å¯¾ã™ã‚‹ã™ã¹ã¦ã®å¤‰æ›´ã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ç›´æ¥å½±éŸ¿ã—ã¾ã™ã€‚è¤‡æ•°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ã®å¤‰æ›´ãŒå•é¡Œã‚’å¼•ãèµ·ã“ã•ãªã„ã‚ˆã†ã«ã€è¿”ã‚Šå€¤ãŒã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ç°¡å˜ã«è¨€ãˆã°ã€è¿”ã‚Šå€¤ã¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚

> [!Warning]
> ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã§ãªã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã« `st.cache_resource` ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚„ãƒ‡ãƒ¼ã‚¿ã®ç ´æãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚è©³ç´°ã¯[ãƒŸãƒ¥ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨ç«¶åˆçŠ¶æ…‹ã®å•é¡Œ](#mutation-and-concurrency-issues)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

- ã‚³ãƒ”ãƒ¼ãŒä½œæˆã•ã‚Œãªã„ãŸã‚ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸè¿”ã‚Šå€¤ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒ1ã¤ã ã‘å­˜åœ¨ã—ã€ç‰¹ã«å¤§è¦æ¨¡ãªæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã«ãƒ¡ãƒ¢ãƒªãŒç¯€ç´„ã•ã‚Œã¾ã™ã€‚ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®ç”¨èªã§ã¯ã€[ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³](https://en.wikipedia.org/wiki/Singleton_pattern)ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚
- é–¢æ•°ã®è¿”ã‚Šå€¤ã¯ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ã§ã‚ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®å‹•ä½œã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ«ã€ã‚¹ãƒ¬ãƒƒãƒ‰ãªã©ã€ã‚‚ã¨ã‚‚ã¨ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã§ããªã„å‹ã«å¯¾ã—ã¦éå¸¸ã«æœ‰åŠ¹ã§ã™ã€‚ã“ã‚Œã‚‰ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ `st.cache_data` ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚

#### ä½¿ç”¨ä¾‹

**ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š**

`st.cache_resource` ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«éå¸¸ã«ä¾¿åˆ©ã§ã™ã€‚é€šå¸¸ã€ã‚¯ã‚¨ãƒªã”ã¨ã«å†åˆ©ç”¨ã—ãŸã„æ¥ç¶šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚æ¯å›æ–°ã—ã„æ¥ç¶šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã™ã‚‹ã®ã¯éåŠ¹ç‡ã§ã€æ¥ç¶šã‚¨ãƒ©ãƒ¼ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚ŒãŒã¾ã•ã« `st.cache_resource` ã®ç”¨é€”ã§ã™ã€‚ä¾‹ãˆã°ã€Postgresãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´åˆï¼š

```python
@st.cache_resource
def init_connection():
    host = "hh-pgsql-public.ebi.ac.uk"
    database = "pfmegrnargs"
    user = "reader"
    password = "NWDMCE5xdipIjRrp"
    return psycopg2.connect(host=host, database=database, user=user, password=password)

conn = init_connection()
```

ã‚‚ã¡ã‚ã‚“ã€ä»–ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã‚‚åŒæ§˜ã«ã§ãã¾ã™ã€‚è©³ç´°ãªä¾‹ã«ã¤ã„ã¦ã¯ã€[Streamlitã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¥ç¶šæ–¹æ³•ã«é–¢ã™ã‚‹ã‚¬ã‚¤ãƒ‰](/develop/tutorials/databases) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚


**æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿**

ã‚¢ãƒ—ãƒªã¯æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å¸¸ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãã†ã—ãªã„ã¨ã€æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ãŒãƒ¡ãƒ¢ãƒªã«å†åº¦èª­ã¿è¾¼ã¾ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚ğŸ¤— Hugging Faceãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã®[ä¾‹](#usage-1)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚PyTorchã‚„TensorFlowã§ã‚‚åŒæ§˜ã«ã§ãã¾ã™ã€‚ä»¥ä¸‹ã¯PyTorchã®ä¾‹ã§ã™ï¼š

```python
@st.cache_resource
def load_model():
    model = torchvision.models.resnet50(weights=ResNet50_Weights.DEFAULT)
    model.eval()
    return model

model = load_model()
```

### ã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã®åˆ¤æ–­

ä¸Šè¨˜ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€ãã‚Œãã‚Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã«å…±é€šã™ã‚‹å¤šãã®ä¾‹ã‚’ç¤ºã—ã¾ã—ãŸãŒã€ã©ã¡ã‚‰ã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã™ã¹ãã‹æ±ºå®šã™ã‚‹ã®ãŒé›£ã—ã„ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚‚å­˜åœ¨ã—ã¾ã™ã€‚æœ€çµ‚çš„ã«ã¯ã€ã€Œãƒ‡ãƒ¼ã‚¿ã€ã¨ã€Œãƒªã‚½ãƒ¼ã‚¹ã€ã®é•ã„ã«å¸°ç€ã—ã¾ã™ï¼š

- ãƒ‡ãƒ¼ã‚¿ã¯ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã™ï¼ˆ[pickle](https://docs.python.org/3/library/pickle.html)ã‚’ä»‹ã—ã¦ãƒã‚¤ãƒˆã«å¤‰æ›å¯èƒ½ï¼‰ã€‚ãƒ‡ã‚£ã‚¹ã‚¯ã«ç°¡å˜ã«ä¿å­˜ã§ãã‚‹ã‚‚ã®ã‚’æŒ‡ã—ã¾ã™ã€‚é€šå¸¸ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã«ä¿å­˜ã™ã‚‹åŸºæœ¬çš„ãªå‹ï¼ˆstrã€intã€floatãªã©ï¼‰ã€ã¾ãŸã¯é…åˆ—ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€ç”»åƒãªã©ã€ã“ã‚Œã‚‰ã®å‹ã‚’çµ„ã¿åˆã‚ã›ãŸãƒªã‚¹ãƒˆã€ã‚¿ãƒ—ãƒ«ã€è¾æ›¸ãªã©ãŒå«ã¾ã‚Œã¾ã™ã€‚
- ãƒªã‚½ãƒ¼ã‚¹ã¯ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºä¸å¯èƒ½ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã€é€šå¸¸ã¯ãƒ‡ã‚£ã‚¹ã‚¯ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ãªã„ã‚‚ã®ã§ã™ã€‚ãƒªã‚½ãƒ¼ã‚¹ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ«ã€ã‚¹ãƒ¬ãƒƒãƒ‰ãªã©ã®ã‚ˆã‚Šè¤‡é›‘ã§ä¸€æ™‚çš„ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚

ä¸Šè¨˜ã®å‹ãƒªã‚¹ãƒˆã‹ã‚‰ã€Pythonã®ã»ã¨ã‚“ã©ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒã€Œãƒ‡ãƒ¼ã‚¿ã€ã§ã‚ã‚‹ã“ã¨ã¯æ˜ã‚‰ã‹ã§ã™ã€‚ã“ã‚ŒãŒ `st.cache_data` ãŒã»ã¨ã‚“ã©ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§æ­£ã—ã„ã‚³ãƒãƒ³ãƒ‰ã§ã‚ã‚‹ç†ç”±ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚`st.cache_resource` ã¯ã€ç‰¹å®šã®çŠ¶æ³ã§ã®ã¿ä½¿ç”¨ã™ã¹ãã‚„ã‚„ç‰¹æ®Šãªã‚³ãƒãƒ³ãƒ‰ã§ã™ã€‚

ã‚ã‚‹ã„ã¯ã€ã‚ã¾ã‚Šè€ƒãˆãŸããªã„å ´åˆã¯ã€ä»¥ä¸‹ã®è¡¨ã‚’å‚ç…§ã—ã¦ã€ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚„è¿”ã‚Šå€¤ã®å‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ğŸ˜‰ï¼š

| ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹                             |                                                                                                       å…¸å‹çš„ãªè¿”ã‚Šå€¤ã®å‹ |                                                                                                                                            æ¨å¥¨ã•ã‚Œã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ |
| :----------------------------------- | -------------------------------------------------------------------------------------------------------------------------: | -----------------------------------------------------------------------------------------------------------------------------------------------------------: |
| pd.read_csv ã§CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€  |                                                                                                           pandas.DataFrame |                                                                                                                                                st.cache_data |
| ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€            |                                                                                                           str, list of str |                                                                                                                                                st.cache_data |
| pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å¤‰æ›ã™ã‚‹         |                                                                                            pandas.DataFrame, pandas.Series |                                                                                                                                                st.cache_data |
| numpyé…åˆ—ã‚’ä½¿ã£ã¦è¨ˆç®—ã™ã‚‹             |                                                                                                              numpy.ndarray |                                                                                                                                                st.cache_data |
| åŸºæœ¬çš„ãªå‹ã‚’ä½¿ã£ãŸå˜ç´”ãªè¨ˆç®—           |                                                                                                         str, int, float, â€¦ |                                                                                                                                                st.cache_data |
| ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¯ã‚¨ãƒªã‚’é€ä¿¡ã™ã‚‹         |                                                                                                           pandas.DataFrame |                                                                                                                                                st.cache_data |
| APIã«ã‚¯ã‚¨ãƒªã‚’é€ä¿¡ã™ã‚‹                  |                                                                                                pandas.DataFrame, str, dict |                                                                                                                                                st.cache_data |
| æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¨è«–ï¼‰ã‚’å®Ÿè¡Œã™ã‚‹      |                                                                                     pandas.DataFrame, str, int, dict, list |                                                                                                                                                st.cache_data |
| ç”»åƒã‚’ä½œæˆã¾ãŸã¯å‡¦ç†ã™ã‚‹               |                                                                                             PIL.Image.Image, numpy.ndarray |                                                                                                                                                st.cache_data |
| ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹                       |                                                        matplotlib.figure.Figure, plotly.graph_objects.Figure, altair.Chart | st.cache_dataï¼ˆãŸã ã—ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã‚ˆã£ã¦ã¯ã€ã‚°ãƒ©ãƒ•ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºä¸å¯èƒ½ãªãŸã‚ã€st.cache_resource ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚ä½œæˆå¾Œã«ã‚°ãƒ©ãƒ•ã‚’å¤‰æ›´ã—ãªã„ã§ãã ã•ã„ï¼ï¼‰ |
| æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€               |                                                             transformers.Pipeline, torch.nn.Module, tensorflow.keras.Model |                                                                                                                                            st.cache_resource |
| ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’åˆæœŸåŒ–ã™ã‚‹           | pyodbc.Connection, sqlalchemy.engine.base.Engine, psycopg2.connection, mysql.connector.MySQLConnection, sqlite3.Connection |                                                                                                                                            st.cache_resource |
| æ°¸ç¶šçš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ«ã‚’é–‹ã         |                                                                                                         \_io.TextIOWrapper |                                                                                                                                            st.cache_resource |
| æ°¸ç¶šçš„ãªã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹ã                 |                                                                                                           threading.thread |                                                                                                                                            st.cache_resource |


## é«˜åº¦ãªä½¿ã„æ–¹

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚µã‚¤ã‚ºã¨æœŸé–“ã®åˆ¶å¾¡

ã‚¢ãƒ—ãƒªãŒé•·æ™‚é–“å®Ÿè¡Œã•ã‚Œã€é–¢æ•°ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ç¶šã‘ã‚‹ã¨ã€æ¬¡ã®2ã¤ã®å•é¡Œã«ç›´é¢ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼š

1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤§ãã™ãã¦ãƒ¡ãƒ¢ãƒªä¸è¶³ã«ãªã‚‹ã€‚
2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå¤ããªã‚‹ï¼ˆä¾‹ï¼šå¤ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã—ã¾ã†ï¼‰ã€‚

ã“ã‚Œã‚‰ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€ä¸¡æ–¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ä½¿ç”¨ã§ãã‚‹ `ttl` ã¨ `max_entries` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ã€‚


**`ttl`ï¼ˆtime-to-liveï¼‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**

`ttl` ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•°ã«æœ‰åŠ¹æœŸé™ã‚’è¨­å®šã—ã¾ã™ã€‚ã“ã®æœŸé™ãŒåˆ‡ã‚Œã€é–¢æ•°ãŒå†åº¦å‘¼ã³å‡ºã•ã‚Œã‚‹ã¨ã€ã‚¢ãƒ—ãƒªã¯å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥å€¤ã‚’ç ´æ£„ã—ã€é–¢æ•°ã‚’å†å®Ÿè¡Œã—ã¾ã™ã€‚ãã®å¾Œã€æ–°ãŸã«è¨ˆç®—ã•ã‚ŒãŸå€¤ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ã“ã®å‹•ä½œã¯ã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’é˜²æ­¢ã™ã‚‹ï¼ˆå•é¡Œ2ï¼‰ãŠã‚ˆã³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤§ãããªã‚Šã™ãã‚‹ã®ã‚’é˜²ãï¼ˆå•é¡Œ1ï¼‰ãŸã‚ã«å½¹ç«‹ã¡ã¾ã™ã€‚ç‰¹ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹å ´åˆã€`ttl` ã‚’è¨­å®šã—ã¦å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãªã„ã‚ˆã†ã«ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚æ¬¡ã®ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
@st.cache_data(ttl=3600)  # ğŸ‘ˆ ãƒ‡ãƒ¼ã‚¿ã‚’1æ™‚é–“ï¼ˆ=3600ç§’ï¼‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_api_data():
    data = api.get(...)
    return data
```

> [!Tip]
> `ttl` ã®å€¤ã‚’ `timedelta` ã‚’ä½¿ã£ã¦è¨­å®šã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ä¾‹ãˆã° `ttl=datetime.timedelta(hours=1)` ã®ã‚ˆã†ã«ã—ã¾ã™ã€‚


**`max_entries` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**

`max_entries` ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã®ã‚¨ãƒ³ãƒˆãƒªæ•°ã®æœ€å¤§å€¤ã‚’è¨­å®šã—ã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªæ•°ã®ä¸Šé™ã‚’è¨­å®šã™ã‚‹ã“ã¨ã¯ã€ç‰¹ã«å¤§ããªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹å ´åˆã«ãƒ¡ãƒ¢ãƒªã‚’åˆ¶é™ã™ã‚‹ãŸã‚ã«å½¹ç«‹ã¡ã¾ã™ï¼ˆå•é¡Œ1ï¼‰ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæº€æ¯ã«ãªã‚‹ã¨ã€æœ€ã‚‚å¤ã„ã‚¨ãƒ³ãƒˆãƒªãŒå‰Šé™¤ã•ã‚Œã€æ–°ã—ã„ã‚¨ãƒ³ãƒˆãƒªãŒè¿½åŠ ã•ã‚Œã¾ã™ã€‚æ¬¡ã®ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
@st.cache_data(max_entries=1000)  # ğŸ‘ˆ ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã®ã‚¨ãƒ³ãƒˆãƒªã‚’æœ€å¤§1000ã«åˆ¶é™
def get_large_array(seed):
    np.random.seed(seed)
    arr = np.random.rand(100000)
    return arr
```

### ã‚¹ãƒ”ãƒŠãƒ¼ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•°ãŒå®Ÿè¡Œä¸­ã«Streamlitã¯ã‚¢ãƒ—ãƒªå†…ã«å°ã•ãªãƒ­ãƒ¼ãƒ‰ã‚¹ãƒ”ãƒŠãƒ¼ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚`show_spinner` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€ã“ã‚Œã‚’ç°¡å˜ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™ã€‚ã“ã‚Œã¯ã€ä¸¡æ–¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ä½¿ç”¨å¯èƒ½ã§ã™ï¼š

```python
@st.cache_data(show_spinner=False)  # ğŸ‘ˆ ã‚¹ãƒ”ãƒŠãƒ¼ã‚’ç„¡åŠ¹ã«ã™ã‚‹
def get_api_data():
    data = api.get(...)
    return data

@st.cache_data(show_spinner="APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")  # ğŸ‘ˆ ã‚¹ãƒ”ãƒŠãƒ¼ã«ã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
def get_api_data():
    data = api.get(...)
    return data
```

### å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é™¤å¤–

ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•°ã§ã¯ã€ã™ã¹ã¦ã®å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãƒãƒƒã‚·ãƒ¥å¯èƒ½ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã“ã§ã¯ã€ãã®ç†ç”±ã¨æ„å‘³ã‚’ç°¡å˜ã«èª¬æ˜ã—ã¾ã™ã€‚é–¢æ•°ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹ã¨ã€Streamlitã¯ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ã‚’è¦‹ã¦ã€ä»¥å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚ãã®ãŸã‚ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ã‚’é–¢æ•°å‘¼ã³å‡ºã—é–“ã§æ¯”è¼ƒã™ã‚‹ä¿¡é ¼æ€§ã®ã‚ã‚‹æ–¹æ³•ãŒå¿…è¦ã§ã™ã€‚æ–‡å­—åˆ—ã‚„æ•´æ•°ã®å ´åˆã¯ç°¡å˜ã§ã™ãŒã€ä»»æ„ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯è¤‡é›‘ã§ã™ã€‚Streamlitã¯[ãƒãƒƒã‚·ãƒ¥åŒ–](https://en.wikipedia.org/wiki/Hash_function)ã‚’ä½¿ç”¨ã—ã¦ã“ã®å•é¡Œã‚’è§£æ±ºã—ã¾ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®‰å®šã—ãŸã‚­ãƒ¼ã«å¤‰æ›ã—ã€ãã®ã‚­ãƒ¼ã‚’ä¿å­˜ã—ã¾ã™ã€‚æ¬¡ã®é–¢æ•°å‘¼ã³å‡ºã—ã§ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å†åº¦ãƒãƒƒã‚·ãƒ¥åŒ–ã—ã€ä¿å­˜ã•ã‚ŒãŸãƒãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã¨æ¯”è¼ƒã—ã¾ã™ã€‚

ã—ã‹ã—ã€ã™ã¹ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãƒãƒƒã‚·ãƒ¥å¯èƒ½ãªã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€ãƒãƒƒã‚·ãƒ¥ä¸å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚„æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•°ã«æ¸¡ã™å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å ´åˆã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é™¤å¤–ã§ãã¾ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã®å‰ã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹ã ã‘ã§ï¼ˆä¾‹ï¼š`_param1`ï¼‰ã€ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã¯ä½¿ç”¨ã•ã‚Œã¾ã›ã‚“ã€‚ä»–ã®ã™ã¹ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸€è‡´ã™ã‚Œã°ã€ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤‰ã‚ã£ã¦ã„ã¦ã‚‚Streamlitã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçµæœã‚’è¿”ã—ã¾ã™ã€‚

ä»¥ä¸‹ã¯ãã®ä¾‹ã§ã™ï¼š

```python
@st.cache_data
def fetch_data(_db_connection, num_rows):  # ğŸ‘ˆ _db_connection ã‚’ãƒãƒƒã‚·ãƒ¥åŒ–ã—ãªã„
    data = _db_connection.fetch(num_rows)
    return data

connection = init_connection()
fetch_data(connection, 10)
```

ã—ã‹ã—ã€ãƒãƒƒã‚·ãƒ¥ä¸å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚‹é–¢æ•°ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ãŸã„å ´åˆã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã—ã‚‡ã†ã‹ï¼Ÿä¾‹ãˆã°ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€ãã®ãƒ¢ãƒ‡ãƒ«ã®å±¤ã®åå‰ã‚’è¿”ã™é–¢æ•°ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ãŸã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ãŒå”¯ä¸€ã®å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚‹ãŸã‚ã€ãã‚Œã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰é™¤å¤–ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚ã“ã®å ´åˆã€`hash_funcs` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚«ã‚¹ã‚¿ãƒ ãƒãƒƒã‚·ãƒ¥é–¢æ•°ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

### `hash_funcs` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

å‰è¿°ã®ã¨ãŠã‚Šã€Streamlitã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•°ã®ã‚·ã‚°ãƒãƒãƒ£ã‚’ãƒãƒƒã‚·ãƒ¥ã—ã¦ã€é–¢æ•°ãŒä»¥å‰ã«å®Ÿè¡Œã•ã‚Œã¦çµæœãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‹ï¼ˆã€Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã€ï¼‰ã€ã¾ãŸã¯å†å®Ÿè¡ŒãŒå¿…è¦ã‹ï¼ˆã€Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã€ï¼‰ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚Streamlitã®ãƒãƒƒã‚·ãƒ¥å‡¦ç†ãŒã§ããªã„å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€åå‰ã®å‰ã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã¦ç„¡è¦–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãŸã ã—ã€2ã¤ã®ç¨€ãªã‚±ãƒ¼ã‚¹ã§ã¯ã€ã“ã‚Œã¯æœ›ã¾ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚ã¤ã¾ã‚Šã€StreamlitãŒãƒãƒƒã‚·ãƒ¥ã§ããªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒƒã‚·ãƒ¥ã—ãŸã„å ´åˆã§ã™ï¼š

1. Streamlitã®ãƒãƒƒã‚·ãƒ¥ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥ã«å¤±æ•—ã—ã€`UnhashableParamError` ãŒç™ºç”Ÿã™ã‚‹å ´åˆã€‚
2. ç‰¹å®šã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¯¾ã—ã¦Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒãƒƒã‚·ãƒ¥ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä¸Šæ›¸ãã—ãŸã„å ´åˆã€‚

ã“ã‚Œã‚‰ã®ã‚±ãƒ¼ã‚¹ã‚’ãã‚Œãã‚Œä¾‹ã‚’ä½¿ã£ã¦èª¬æ˜ã—ã¾ã™ã€‚


#### ä¾‹1: ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ã®ãƒãƒƒã‚·ãƒ¥

Streamlitã¯ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ã®ãƒãƒƒã‚·ãƒ¥æ–¹æ³•ã‚’çŸ¥ã‚Šã¾ã›ã‚“ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•°ã«ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ã‚’æ¸¡ã™ã¨ã€Streamlitã¯ `UnhashableParamError` ã‚’ç™ºç”Ÿã•ã›ã¾ã™ã€‚ä¾‹ãˆã°ã€åˆæœŸã®æ•´æ•°ã‚¹ã‚³ã‚¢ã‚’å—ã‘å–ã‚‹ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ `MyCustomClass` ã‚’å®šç¾©ã—ã€ã‚¹ã‚³ã‚¢ã‚’ä¹—æ•°ã§æ›ã‘ã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•° `multiply_score` ã‚’å®šç¾©ã—ã¾ã™ï¼š

```python
import streamlit as st

class MyCustomClass:
    def __init__(self, initial_score: int):
        self.my_score = initial_score

@st.cache_data
def multiply_score(obj: MyCustomClass, multiplier: int) -> int:
    return obj.my_score * multiplier

initial_score = st.number_input("Enter initial score", value=15)

score = MyCustomClass(initial_score)
multiplier = 2

st.write(multiply_score(score, multiplier))
```

ã“ã®ã‚¢ãƒ—ãƒªã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€StreamlitãŒ `UnhashableParamError` ã‚’ç™ºç”Ÿã•ã›ã‚‹ã®ãŒã‚ã‹ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ã€`MyCustomClass` ã®ãƒãƒƒã‚·ãƒ¥æ–¹æ³•ã‚’StreamlitãŒçŸ¥ã‚‰ãªã„ãŸã‚ã§ã™ï¼š

```python
UnhashableParamError: Cannot hash argument 'obj' (of type __main__.MyCustomClass) in 'multiply_score'.
```

ã“ã‚Œã‚’ä¿®æ­£ã™ã‚‹ã«ã¯ã€`hash_funcs` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ `MyCustomClass` ã®ãƒãƒƒã‚·ãƒ¥æ–¹æ³•ã‚’Streamlitã«ä¼ãˆã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã«ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã¨ãƒãƒƒã‚·ãƒ¥é–¢æ•°ã®å¯¾å¿œã‚’æŒã¤è¾æ›¸ã‚’ `hash_funcs` ã«æ¸¡ã—ã¾ã™ã€‚ã©ã®ãƒãƒƒã‚·ãƒ¥é–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã¯é–‹ç™ºè€…ãŒé¸æŠã§ãã¾ã™ã€‚ã“ã®å ´åˆã€ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€ãã®ã‚¹ã‚³ã‚¢ã‚’è¿”ã™ã‚«ã‚¹ã‚¿ãƒ ãƒãƒƒã‚·ãƒ¥é–¢æ•° `hash_func` ã‚’å®šç¾©ã—ã¾ã—ã‚‡ã†ã€‚ã‚¹ã‚³ã‚¢ãŒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸€æ„ã®è­˜åˆ¥å­ã¨ã—ã¦ä½¿ç”¨ã§ãã‚‹ãŸã‚ã€ãã‚Œã‚’ä½¿ç”¨ã—ã¦ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ±ºå®šè«–çš„ã«ãƒãƒƒã‚·ãƒ¥ã—ã¾ã™ï¼š

```python
import streamlit as st

class MyCustomClass:
    def __init__(self, initial_score: int):
        self.my_score = initial_score

def hash_func(obj: MyCustomClass) -> int:
    return obj.my_score  # ã¾ãŸã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¸€æ„ã«è­˜åˆ¥ã™ã‚‹ä»–ã®å€¤

@st.cache_data(hash_funcs={MyCustomClass: hash_func})
def multiply_score(obj: MyCustomClass, multiplier: int) -> int:
    return obj.my_score * multiplier

initial_score = st.number_input("Enter initial score", value=15)

score = MyCustomClass(initial_score)
multiplier = 2

st.write(multiply_score(score, multiplier))
```

ã“ã‚Œã§ã‚¢ãƒ—ãƒªã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€Streamlitã¯ `UnhashableParamError` ã‚’ç™ºç”Ÿã•ã›ãšã€ã‚¢ãƒ—ãƒªãŒæœŸå¾…é€šã‚Šã«å‹•ä½œã—ã¾ã™ã€‚

æ¬¡ã«ã€`multiply_score` ãŒ `MyCustomClass` ã®å±æ€§ã§ã‚ã‚Šã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’ãƒãƒƒã‚·ãƒ¥ã—ãŸã„å ´åˆã‚’è€ƒãˆã¾ã™ï¼š

```python
import streamlit as st

class MyCustomClass:
    def __init__(self, initial_score: int):
        self.my_score = initial_score

    @st.cache_data
    def multiply_score(self, multiplier: int) -> int:
        return self.my_score * multiplier

initial_score = st.number_input("Enter initial score", value=15)

score = MyCustomClass(initial_score)
multiplier = 2

st.write(score.multiply_score(multiplier))
```

ã“ã®ã‚¢ãƒ—ãƒªã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€StreamlitãŒ `UnhashableParamError` ã‚’ç™ºç”Ÿã•ã›ã‚‹ã®ãŒã‚ã‹ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ã€`multiply_score` å†…ã® `self` ãŒãƒãƒƒã‚·ãƒ¥ã§ããªã„ãŸã‚ã§ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ç°¡å˜ãªæ–¹æ³•ã¯ã€Pythonã® `hash()` é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã§ã™ï¼š

```python
import streamlit as st

class MyCustomClass:
    def __init__(self, initial_score: int):
        self.my_score = initial_score

    @st.cache_data(hash_funcs={"__main__.MyCustomClass": lambda x: hash(x.my_score)})
    def multiply_score(self, multiplier: int) -> int:
        return self.my_score * multiplier

initial_score = st.number_input("Enter initial score", value=15)

score = MyCustomClass(initial_score)
multiplier = 2

st.write(score.multiply_score(multiplier))
```

ä¸Šè¨˜ã§ã¯ã€ãƒãƒƒã‚·ãƒ¥é–¢æ•°ã‚’ `lambda x: hash(x.my_score)` ã¨ã—ã¦å®šç¾©ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€`MyCustomClass` ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã® `my_score` å±æ€§ã«åŸºã¥ã„ãŸãƒãƒƒã‚·ãƒ¥ãŒä½œæˆã•ã‚Œã¾ã™ã€‚`my_score` ãŒåŒã˜ã§ã‚ã‚Œã°ã€ãƒãƒƒã‚·ãƒ¥ã‚‚åŒã˜ã§ã™ã€‚ãã®ãŸã‚ã€`multiply_score` ã®çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å†å–å¾—ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚

ã‚‚ã—Pythonã® `id()` é–¢æ•°ã‚’ä½¿ã£ã¦ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒãƒƒã‚·ãƒ¥ã—ãŸããªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€ä»¥ä¸‹ã®ã‚ˆã†ã«æ›¸ãã“ã¨ãŒã§ãã¾ã™ï¼š

```python
import streamlit as st

class MyCustomClass:
    def __init__(self, initial_score: int):
        self.my_score = initial_score

    @st.cache_data(hash_funcs={"__main__.MyCustomClass": id})
    def multiply_score(self, multiplier: int) -> int:
        return self.my_score * multiplier

initial_score = st.number_input("Enter initial score", value=15)

score = MyCustomClass(initial_score)
multiplier = 2

st.write(score.multiply_score(multiplier))
```

ã“ã®ã‚¢ãƒ—ãƒªã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€`my_score` ãŒå¤‰ã‚ã£ã¦ã„ãªãã¦ã‚‚ `multiply_score` ãŒæ¯å›å†è¨ˆç®—ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ãªãœã§ã—ã‚‡ã†ã‹ï¼ŸPythonã§ã¯ã€`id()` ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸€æ„ã®è­˜åˆ¥å­ã‚’è¿”ã—ã€ãã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç”Ÿå­˜æœŸé–“ä¸­ã«å¤‰æ›´ã•ã‚Œã¾ã›ã‚“ã€‚ã¤ã¾ã‚Šã€`MyCustomClass` ã®2ã¤ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹é–“ã§ `my_score` ã®å€¤ãŒåŒã˜ã§ã‚ã£ã¦ã‚‚ã€`id()` ã¯ç•°ãªã‚‹å€¤ã‚’è¿”ã™ãŸã‚ã€ç•°ãªã‚‹ãƒãƒƒã‚·ãƒ¥å€¤ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚çµæœã¨ã—ã¦ã€Streamlitã¯ã“ã‚Œã‚‰ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆ¥ã€…ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå€¤ãŒå¿…è¦ãªã‚‚ã®ã¨ã—ã¦æ‰±ã„ã€`my_score` ãŒå¤‰ã‚ã£ã¦ã„ãªãã¦ã‚‚ `multiply_score` ã‚’æ¯å›å†è¨ˆç®—ã—ã¾ã™ã€‚

ã“ã®ãŸã‚ã€`id()` ã‚’ãƒãƒƒã‚·ãƒ¥é–¢æ•°ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯æ¨å¥¨ã•ã‚Œãšã€æ±ºå®šè«–çš„ã§çœŸã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¿”ã™é–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚ã—ã‹ã—ã€ã‚‚ã—é©åˆ‡ãªçŸ¥è­˜ã‚’æŒã£ã¦ã„ã‚‹å ´åˆã¯ã€`id()` ã‚’ãƒãƒƒã‚·ãƒ¥é–¢æ•°ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ãŸã ã—ã€ãã®å½±éŸ¿ã«ã¤ã„ã¦ã¯ååˆ†ã«ç†è§£ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€`id()` ã¯ã€`@st.cache_resource` é–¢æ•°ã®çµæœã‚’åˆ¥ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢æ•°ã¸ã®å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦æ¸¡ã™å ´åˆã«é©åˆ‡ãªãƒãƒƒã‚·ãƒ¥é–¢æ•°ã§ã™ã€‚ã“ã‚Œã¯ã€ãƒãƒƒã‚·ãƒ¥ä¸å¯èƒ½ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—å…¨ä½“ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚

#### Example 2: Hashing a Pydantic model

Let's consider another example where we want to hash a Pydantic model:

```python
import streamlit as st
from pydantic import BaseModel

class Person(BaseModel):
    name: str

@st.cache_data
def identity(person: Person):
    return person

person = identity(Person(name="Lee"))
st.write(f"The person is {person.name}")
```

Above, we define a custom class `Person` using Pydantic's `BaseModel` with a single attribute name. We also define an `identity` function which accepts an instance of `Person` as an arg and returns it without modification. This function is intended to cache the result, therefore, if called multiple times with the same `Person` instance, it won't recompute but return the cached instance.

If you run the app, however, you'll run into a `UnhashableParamError: Cannot hash argument 'person' (of type __main__.Person) in 'identity'.` error. This is because Streamlit does not know how to hash the `Person` class. To fix this, we can use the `hash_funcs` kwarg to tell Streamlit how to hash `Person`.

In the version below, we define a custom hash function `hash_func` that takes the `Person` instance as input and returns the name attribute. We want the name to be the unique identifier of the object, so we can use it to deterministically hash the object:

```python
import streamlit as st
from pydantic import BaseModel

class Person(BaseModel):
    name: str

@st.cache_data(hash_funcs={Person: lambda p: p.name})
def identity(person: Person):
    return person

person = identity(Person(name="Lee"))
st.write(f"The person is {person.name}")
```

#### Example 3: Hashing a ML model

There may be cases where you want to pass your favorite machine learning model to a cached function. For example, let's say you want to pass a TensorFlow model to a cached function, based on what model the user selects in the app. You might try something like this:

```python
import streamlit as st
import tensorflow as tf

@st.cache_resource
def load_base_model(option):
    if option == 1:
        return tf.keras.applications.ResNet50(include_top=False, weights="imagenet")
    else:
        return tf.keras.applications.MobileNetV2(include_top=False, weights="imagenet")

@st.cache_resource
def load_layers(base_model):
    return [layer.name for layer in base_model.layers]

option = st.radio("Model 1 or 2", [1, 2])

base_model = load_base_model(option)

layers = load_layers(base_model)

st.write(layers)
```

In the above app, the user can select one of two models. Based on the selection, the app loads the corresponding model and passes it to `load_layers`. This function then returns the names of the layers in the model. If you run the app, you'll see that Streamlit raises a `UnhashableParamError` since it cannot hash the argument `'base_model' (of type keras.engine.functional.Functional) in 'load_layers'`.

If you disable hashing for `base_model` by prepending an underscore to its name, you'll observe that regardless of which base model is chosen, the layers displayed are same. This subtle bug is due to the fact that the `load_layers` function is not re-run when the base model changes. This is because Streamlit does not hash the `base_model` argument, so it does not know that the function needs to be re-run when the base model changes.

To fix this, we can use the `hash_funcs` kwarg to tell Streamlit how to hash the `base_model` argument. In the version below, we define a custom hash function `hash_func`: `Functional: lambda x: x.name`. Our choice of hash func is informed by our knowledge that the `name` attribute of a `Functional` object or model uniquely identifies it. As long as the `name` attribute remains the same, the hash remains the same. Thus, the result of `load_layers` can be retrieved from the cache without recomputation.

```python
import streamlit as st
import tensorflow as tf
from keras.engine.functional import Functional

@st.cache_resource
def load_base_model(option):
    if option == 1:
        return tf.keras.applications.ResNet50(include_top=False, weights="imagenet")
    else:
        return tf.keras.applications.MobileNetV2(include_top=False, weights="imagenet")

@st.cache_resource(hash_funcs={Functional: lambda x: x.name})
def load_layers(base_model):
    return [layer.name for layer in base_model.layers]

option = st.radio("Model 1 or 2", [1, 2])

base_model = load_base_model(option)

layers = load_layers(base_model)

st.write(layers)
```

In the above case, we could also have used `hash_funcs={Functional: id}` as the hash function. This is because `id` is often the _correct_ hash func when you're passing the result of an `@st.cache_resource` function as the input param to another cached function.

#### Example 4: Overriding Streamlit's default hashing mechanism

Let's consider another example where we want to override Streamlit's default hashing mechanism for a pytz-localized datetime object:

```python
from datetime import datetime
import pytz
import streamlit as st

tz = pytz.timezone("Europe/Berlin")

@st.cache_data
def load_data(dt):
    return dt

now = datetime.now()
st.text(load_data(dt=now))

now_tz = tz.localize(datetime.now())
st.text(load_data(dt=now_tz))
```

It may be surprising to see that although `now` and `now_tz` are of the same `<class 'datetime.datetime'>` type, Streamlit does not how to hash `now_tz` and raises a `UnhashableParamError`. In this case, we can override Streamlit's default hashing mechanism for `datetime` objects by passing a custom hash function to the `hash_funcs` kwarg:

```python
from datetime import datetime

import pytz
import streamlit as st

tz = pytz.timezone("Europe/Berlin")

@st.cache_data(hash_funcs={datetime: lambda x: x.strftime("%a %d %b %Y, %I:%M%p")})
def load_data(dt):
    return dt

now = datetime.now()
st.text(load_data(dt=now))

now_tz = tz.localize(datetime.now())
st.text(load_data(dt=now_tz))
```

Let's now consider a case where we want to override Streamlit's default hashing mechanism for NumPy arrays. While Streamlit natively hashes Pandas and NumPy objects, there may be cases where you want to override Streamlit's default hashing mechanism for these objects.

For example, let's say we create a cache-decorated `show_data` function that accepts a NumPy array and returns it without modification. In the bellow app, `data = df["str"].unique()` (which is a NumPy array) is passed to the `show_data` function.

```python
import time
import numpy as np
import pandas as pd
import streamlit as st

@st.cache_data
def get_data():
    df = pd.DataFrame({"num": [112, 112, 2, 3], "str": ["be", "a", "be", "c"]})
    return df

@st.cache_data
def show_data(data):
    time.sleep(2)  # This makes the function take 2s to run
    return data

df = get_data()
data = df["str"].unique()

st.dataframe(show_data(data))
st.button("Re-run")
```

Since `data` is always the same, we expect the `show_data` function to return the cached value. However, if you run the app, and click the `Re-run` button, you'll notice that the `show_data` function is re-run each time. We can assume this behavior is a consequence of Streamlit's default hashing mechanism for NumPy arrays.

To work around this, let's define a custom hash function `hash_func` that takes a NumPy array as input and returns a string representation of the array:

```python
import time
import numpy as np
import pandas as pd
import streamlit as st

@st.cache_data
def get_data():
    df = pd.DataFrame({"num": [112, 112, 2, 3], "str": ["be", "a", "be", "c"]})
    return df

@st.cache_data(hash_funcs={np.ndarray: str})
def show_data(data):
    time.sleep(2)  # This makes the function take 2s to run
    return data

df = get_data()
data = df["str"].unique()

st.dataframe(show_data(data))
st.button("Re-run")
```

Now if you run the app, and click the `Re-run` button, you'll notice that the `show_data` function is no longer re-run each time. It's important to note here that our choice of hash function was very naive and not necessarily the best choice. For example, if the NumPy array is large, converting it to a string representation may be expensive. In such cases, it is up to you as the developer to define what a good hash function is for your use case.

#### Static elements

Since version 1.16.0, cached functions can contain Streamlit commands! For example, you can do this:

```python
@st.cache_data
def get_api_data():
    data = api.get(...)
    st.success("Fetched data from API!")  # ğŸ‘ˆ Show a success message
    return data
```

As we know, Streamlit only runs this function if it hasn't been cached before. On this first run, the `st.success` message will appear in the app. But what happens on subsequent runs? It still shows up! Streamlit realizes that there is an `st.` command inside the cached function, saves it during the first run, and replays it on subsequent runs. Replaying static elements works for both caching decorators.

You can also use this functionality to cache entire parts of your UI:

```python
@st.cache_data
def show_data():
    st.header("Data analysis")
    data = api.get(...)
    st.success("Fetched data from API!")
    st.write("Here is a plot of the data:")
    st.line_chart(data)
    st.write("And here is the raw data:")
    st.dataframe(data)
```

#### Input widgets

You can also use [interactive input widgets](/develop/api-reference/widgets) like `st.slider` or `st.text_input` in cached functions. Widget replay is an experimental feature at the moment. To enable it, you need to set the `experimental_allow_widgets` parameter:

```python
@st.cache_data(experimental_allow_widgets=True)  # ğŸ‘ˆ Set the parameter
def get_data():
    num_rows = st.slider("Number of rows to get")  # ğŸ‘ˆ Add a slider
    data = api.get(..., num_rows)
    return data
```

Streamlit treats the slider like an additional input parameter to the cached function. If you change the slider position, Streamlit will see if it has already cached the function for this slider value. If yes, it will return the cached value. If not, it will rerun the function using the new slider value.

Using widgets in cached functions is extremely powerful because it lets you cache entire parts of your app. But it can be dangerous! Since Streamlit treats the widget value as an additional input parameter, it can easily lead to excessive memory usage. Imagine your cached function has five sliders and returns a 100 MB DataFrame. Then we'll add 100 MB to the cache for _every permutation_ of these five slider values â€“ even if the sliders do not influence the returned data! These additions can make your cache explode very quickly. Please be aware of this limitation if you use widgets in cached functions. We recommend using this feature only for isolated parts of your UI where the widgets directly influence the cached return value.

<Warning>

Support for widgets in cached functions is experimental. We may change or remove it anytime without warning. Please use it with care!
</Warning>

<Note>

Two widgets are currently not supported in cached functions: `st.file_uploader` and `st.camera_input`. We may support them in the future. Feel free to [open a GitHub issue](https://github.com/streamlit/streamlit/issues) if you need them!
</Note>

### Dealing with large data

As we explained, you should cache data objects with `st.cache_data`. But this can be slow for extremely large data, e.g., DataFrames or arrays with >100 million rows. That's because of the [copying behavior](#copying-behavior) of `st.cache_data`: on the first run, it serializes the return value to bytes and deserializes it on subsequent runs. Both operations take time.

If you're dealing with extremely large data, it can make sense to use `st.cache_resource` instead. It does not create a copy of the return value via serialization/deserialization and is almost instant. But watch out: any mutation to the function's return value (such as dropping a column from a DataFrame or setting a value in an array) directly manipulates the object in the cache. You must ensure this doesn't corrupt your data or lead to crashes. See the section on [Mutation and concurrency issues](#mutation-and-concurrency-issues) below.

When benchmarking `st.cache_data` on pandas DataFrames with four columns, we found that it becomes slow when going beyond 100 million rows. The table shows runtimes for both caching decorators at different numbers of rows (all with four columns):

|                   |                 | 10M rows | 50M rows | 100M rows | 200M rows |
| ----------------- | --------------- | :------: | :------: | :-------: | :-------: |
| st.cache_data     | First run\*     |  0.4 s   |   3 s    |   14 s    |   28 s    |
|                   | Subsequent runs |  0.2 s   |   1 s    |    2 s    |    7 s    |
| st.cache_resource | First run\*     |  0.01 s  |  0.1 s   |   0.2 s   |    1 s    |
|                   | Subsequent runs |   0 s    |   0 s    |    0 s    |    0 s    |

|                                                                                                                                                              |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| _\*For the first run, the table only shows the overhead time of using the caching decorator. It does not include the runtime of the cached function itself._ |

### Mutation and concurrency issues

In the sections above, we talked a lot about issues when mutating return objects of cached functions. This topic is complicated! But it's central to understanding the behavior differences between `st.cache_data` and `st.cache_resource`. So let's dive in a bit deeper.

First, we should clearly define what we mean by mutations and concurrency:

- By **mutations**, we mean any changes made to a cached function's return value _after_ that function has been called. I.e. something like this:

  ```python
  @st.cache_data
  def create_list():
      l = [1, 2, 3]

  l = create_list()  # ğŸ‘ˆ Call the function
  l[0] = 2  # ğŸ‘ˆ Mutate its return value
  ```

- By **concurrency**, we mean that multiple sessions can cause these mutations at the same time. Streamlit is a web framework that needs to handle many users and sessions connecting to an app. If two people view an app at the same time, they will both cause the Python script to rerun, which may manipulate cached return objects at the same time â€“ concurrently.

Mutating cached return objects can be dangerous. It can lead to exceptions in your app and even corrupt your data (which can be worse than a crashed app!). Below, we'll first explain the copying behavior of `st.cache_data` and show how it can avoid mutation issues. Then, we'll show how concurrent mutations can lead to data corruption and how to prevent it.

#### Copying behavior

`st.cache_data` creates a copy of the cached return value each time the function is called. This avoids most mutations and concurrency issues. To understand it in detail, let's go back to the [Uber ridesharing example](#usage) from the section on `st.cache_data` above. We are making two modifications to it:

1. We are using `st.cache_resource` instead of `st.cache_data`. `st.cache_resource` does **not** create a copy of the cached object, so we can see what happens without the copying behavior.
2. After loading the data, we manipulate the returned DataFrame (in place!) by dropping the column `"Lat"`.

Here's the code:

```python
@st.cache_resource   # ğŸ‘ˆ Turn off copying behavior
def load_data(url):
    df = pd.read_csv(url)
    return df

df = load_data("https://raw.githubusercontent.com/plotly/datasets/master/uber-rides-data1.csv")
st.dataframe(df)

df.drop(columns=['Lat'], inplace=True)  # ğŸ‘ˆ Mutate the dataframe inplace

st.button("Rerun")
```

Let's run it and see what happens! The first run should work fine. But in the second run, you see an exception: `KeyError: "['Lat'] not found in axis"`. Why is that happening? Let's go step by step:

- On the first run, Streamlit runs `load_data` and stores the resulting DataFrame in the cache. Since we're using `st.cache_resource`, it does **not** create a copy but stores the original DataFrame.
- Then we drop the column `"Lat"` from the DataFrame. Note that this is dropping the column from the _original_ DataFrame stored in the cache. We are manipulating it!
- On the second run, Streamlit returns that exact same manipulated DataFrame from the cache. It does not have the column `"Lat"` anymore! So our call to `df.drop` results in an exception. Pandas cannot drop a column that doesn't exist.

The copying behavior of `st.cache_data` prevents this kind of mutation error. Mutations can only affect a specific copy and not the underlying object in the cache. The next rerun will get its own, unmutated copy of the DataFrame. You can try it yourself, just replace `st.cache_resource` with `st.cache_data` above, and you'll see that everything works.

Because of this copying behavior,Â `st.cache_data`Â is the recommended way to cache data transforms and computations â€“ anything that returns a serializable object.

#### Concurrency issues

Now let's look at what can happen when multiple users concurrently mutate an object in the cache. Let's say you have a function that returns a list. Again, we are using `st.cache_resource` to cache it so that we are not creating a copy:

```python
@st.cache_resource
def create_list():
    l = [1, 2, 3]
    return l

l = create_list()
first_list_value = l[0]
l[0] = first_list_value + 1

st.write("l[0] is:", l[0])
```

Let's say user A runs the app. They will see the following output:

```python
l[0] is: 2
```

Let's say another user, B, visits the app right after. In contrast to user A, they will see the following output:

```python
l[0] is: 3
```

Now, user A reruns the app immediately after user B. They will see the following output:

```python
l[0] is: 4
```

What is happening here? Why are all outputs different?

- When user A visits the app,Â `create_list()`Â is called, and the listÂ `[1, 2, 3]`Â is stored in the cache. This list is then returned to user A. The first value of the list, `1`, is assigned to `first_list_value` , and `l[0]`Â is changed to `2`.
- When user B visits the app,Â `create_list()`Â returns the mutated list from the cache:Â `[2, 2, 3]`. The first value of the list, `2`, is assigned to `first_list_value` and `l[0]`Â is changed to `3`.
- When user A reruns the app,Â `create_list()`Â returns the mutated list again:Â `[3, 2, 3]`. The first value of the list, `3`, is assigned to `first_list_value,` and `l[0]`Â is changed to 4.

If you think about it, this makes sense. Users A and B use the same list object (the one stored in the cache). And since the list object is mutated, user A's change to the list object is also reflected in user B's app.

This is why you must be careful about mutating objects cached with `st.cache_resource`, especially when multiple users access the app concurrently. If we had usedÂ `st.cache_data`Â instead ofÂ `st.cache_resource`, the app would have copied the list object for each user, and the above example would have worked as expected â€“ users A and B would have both seen:

```python
l[0] is: 2
```

<Note>

This toy example might seem benign. But data corruption can be extremely dangerous! Imagine we had worked with the financial records of a large bank here. You surely don't want to wake up with less money on your account just because someone used the wrong caching decorator ğŸ˜‰

</Note>

## Migrating from st.cache

We introduced the caching commands described above in Streamlit 1.18.0. Before that, we had one catch-all command `st.cache`. Using it was often confusing, resulted in weird exceptions, and was slow. That's why we replaced `st.cache` with the new commands in 1.18.0 (read more in this [blog post](https://blog.streamlit.io/introducing-two-new-caching-commands-to-replace-st-cache/)). The new commands provide a more intuitive and efficient way to cache your data and resources and are intended to replace `st.cache` in all new development.

If your app is still using `st.cache`, don't despair! Here are a few notes on migrating:

- Streamlit will show a deprecation warning if your app uses `st.cache`.
- We will not remove `st.cache` soon, so you don't need to worry about your 2-year-old app breaking. But we encourage you to try the new commands going forward â€“ they will be way less annoying!
- Switching code to the new commands should be easy in most cases. To decide whether to use `st.cache_data` or `st.cache_resource`, read [Deciding which caching decorator to use](#deciding-which-caching-decorator-to-use). Streamlit will also recognize common use cases and show hints right in the deprecation warnings.
- Most parameters from `st.cache` are also present in the new commands, with a few exceptions:
  - `allow_output_mutation` does not exist anymore. You can safely delete it. Just make sure you use the right caching command for your use case.
  - `suppress_st_warning` does not exist anymore. You can safely delete it. Cached functions can now contain Streamlit commands and will replay them. If you want to use widgets inside cached functions, set `experimental_allow_widgets=True`. See [Input widgets](#input-widgets) for an example.

If you have any questions or issues during the migration process, please contact us on the [forum](https://discuss.streamlit.io/), and we will be happy to assist you. ğŸˆ
